{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "torch.Size([120, 4]) torch.Size([30, 4]) torch.Size([120]) torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, Y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, stratify=Y, random_state=123)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = torch.tensor(X_train, dtype=torch.float32),torch.tensor(X_test, dtype=torch.float32),torch.tensor(Y_train, dtype=torch.long),torch.tensor(Y_test, dtype=torch.long)\n",
    "\n",
    "samples, features = X_train.shape\n",
    "classes = Y_test.unique()\n",
    "print(features)\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "\n",
    "X_train = (X_train - mean)/ std\n",
    "X_test = (X_test - mean)/ std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.first_layer = nn.Linear(features, 5)\n",
    "        self.second_layer = nn.Linear(5, 10)\n",
    "        self.third_layer = nn.Linear(10, 15)\n",
    "        self.final_layer = nn.Linear(15,2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, X_batch):\n",
    "        layer_out = self.relu(self.first_layer(X_batch))\n",
    "        layer_out = self.relu(self.second_layer(layer_out))\n",
    "        layer_out = self.relu(self.third_layer(layer_out))\n",
    "\n",
    "        return self.softmax(self.final_layer(layer_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5363, 0.4637],\n",
       "        [0.5359, 0.4641],\n",
       "        [0.5162, 0.4838],\n",
       "        [0.5408, 0.4592],\n",
       "        [0.5412, 0.4588]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Classifier()\n",
    "preds = classifier(X_train[:5])\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(model, loss_func, optimizer, X, Y, epochs=500):\n",
    "    for i in range(epochs):\n",
    "        preds = model(X) ## Make Predictions by forward pass through network\n",
    "        loss = loss_func(preds, Y) ## Calculate Loss\n",
    "        optimizer.zero_grad() ## Zero weights before calculating gradients\n",
    "        loss.backward() ## Calculate Gradients\n",
    "        optimizer.step() ## Update Weights\n",
    "        if i % 100 == 0: ## Print MSE every 100 epochs\n",
    "            print(\"NegLogLoss : {:.2f}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Target 2 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m nll_loss \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mNLLLoss()\n\u001b[0;32m      7\u001b[0m optimizer \u001b[39m=\u001b[39m SGD(params\u001b[39m=\u001b[39mclassifier\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlearning_rate)\n\u001b[1;32m----> 8\u001b[0m TrainModel(classifier, nll_loss, optimizer, X_train, Y_train, epochs\u001b[39m=\u001b[39;49mepochs)\n",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m, in \u001b[0;36mTrainModel\u001b[1;34m(model, loss_func, optimizer, X, Y, epochs)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m      3\u001b[0m     preds \u001b[39m=\u001b[39m model(X) \u001b[39m## Make Predictions by forward pass through network\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     loss \u001b[39m=\u001b[39m loss_func(preds, Y) \u001b[39m## Calculate Loss\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad() \u001b[39m## Zero weights before calculating gradients\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     loss\u001b[39m.\u001b[39mbackward() \u001b[39m## Calculate Gradients\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:216\u001b[0m, in \u001b[0;36mNLLLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 216\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mnll_loss(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py:2701\u001b[0m, in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2699\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2700\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 2701\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mnll_loss_nd(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index)\n",
      "\u001b[1;31mIndexError\u001b[0m: Target 2 is out of bounds."
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "torch.manual_seed(42) ##For reproducibility.This will make sure that same random weights are initialized each time.\n",
    "epochs = 1500\n",
    "learning_rate = torch.tensor(1/1e2) # 0.01\n",
    "classifier = Classifier()\n",
    "nll_loss = nn.NLLLoss()\n",
    "optimizer = SGD(params=classifier.parameters(), lr=learning_rate)\n",
    "TrainModel(classifier, nll_loss, optimizer, X_train, Y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = classifier(X_test) ## Make Predictions on test dataset\n",
    "test_preds = torch.argmax(test_preds, axis=1) ## Convert Probabilities to class type\n",
    "train_preds = classifier(X_train) ## Make Predictions on train dataset\n",
    "train_preds = torch.argmax(train_preds, axis=1) ## Convert Probabilities to class type\n",
    "test_preds[:5], train_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.33\n",
      "Test  Accuracy : 0.33\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Train Accuracy : {:.2f}\".format(accuracy_score(Y_train, train_preds)))\n",
    "print(\"Test  Accuracy : {:.2f}\".format(accuracy_score(Y_test, test_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50        10\n",
      "           1       0.00      0.00      0.00        10\n",
      "           2       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.33        30\n",
      "   macro avg       0.11      0.33      0.17        30\n",
      "weighted avg       0.11      0.33      0.17        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Test Data Classification Report : \")\n",
    "print(classification_report(Y_test, test_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11 (tags/v3.9.11:2de452f, Mar 16 2022, 14:33:45) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5addf786bcd861d1ce5006f23111f8cbb206731e5b61b0a5632ba9e0252558a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
